{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbbb126-2e76-49f9-b8b1-cfd8e89b42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fc46fd-4044-4ab4-b646-becb867c0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_beta(beta0, i, c=1):\n",
    "    beta = np.log(np.exp(c*beta0)+i)/c\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a8bbe8-9570-4d85-89f1-ef16c515b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = Bounds([0], [np.inf])\n",
    "def langevin(x0, d, func, grad, maxiter = 100, eta0 = 0.001, beta0 = 1, beta_schedule = log_beta, c=1):\n",
    "    \"\"\"\n",
    "    This code implements Gradient Langevin Algorithm with exact linesearch on the step size eta\n",
    "\n",
    "    Args:\n",
    "        x0 (numpy darray): initial point\n",
    "        d (int): dimension of the objective function\n",
    "        func (Callable): objective function\n",
    "        grad (Callable): gradient of objective function\n",
    "        maxiter (int): maximum number of iterations\n",
    "        eta0 (float): initial value for eta\n",
    "        beta0 (float): initial value for beta\n",
    "        beta_schedule (Callable): annealing schedule for temperature\n",
    "        c (float): constant in logarithmic annealing schedule\n",
    "\n",
    "    Output:\n",
    "        f_list (numpy darray): the list of function values for each iteration\n",
    "        x_list (numpy darray): the list of x values for each iteration\n",
    "    \"\"\"\n",
    "    x_list = np.zeros((maxiter,d))\n",
    "    x_list[0,:] = x0\n",
    "    f_list = np.zeros((maxiter,))\n",
    "    f_list[0] = func(x0)\n",
    "    for i in range(1,maxiter):\n",
    "        epsilon = np.random.normal(0, 1, d)\n",
    "        beta = beta_schedule(beta0, i, c=c)\n",
    "        def objective_function(eta):\n",
    "            return func(x_list[i-1,:]- eta*grad(x_list[i-1,:]) + np.sqrt(2*eta/beta)*epsilon)\n",
    "        # perform exact linesearch\n",
    "        result = minimize(objective_function, eta0, method = \"SLSQP\", bounds=bounds)\n",
    "        eta = result.x\n",
    "        x_list[i,:] = x_list[i-1,:] - eta*grad(x_list[i-1,:]) + np.sqrt(2*eta/beta)*epsilon\n",
    "        f_list[i] = func(x_list[i,:])\n",
    "    return f_list, x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4af231-387f-4b7b-b613-94eb3f150d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def underdamped_langevin(x0, \n",
    "                         d, \n",
    "                         func, \n",
    "                         grad, \n",
    "                         maxiter = 100, \n",
    "                         eta0 = 0.001, \n",
    "                         beta0 = 1, \n",
    "                         beta_schedule = log_beta, \n",
    "                         gamma = 0.1, \n",
    "                         c=0.1):\n",
    "    \"\"\"\n",
    "    This code implements Underdamped Langevin Algorithm with exact linesearch on the step size eta\n",
    "\n",
    "    Args:\n",
    "        x0 (numpy darray): initial point\n",
    "        d (int): dimension of the objective function\n",
    "        func (Callable): objective function\n",
    "        grad (Callable): gradient of objective function\n",
    "        maxiter (int): maximum number of iterations\n",
    "        eta0 (float): initial value for eta\n",
    "        beta0 (float): initial value for beta\n",
    "        beta_schedule (Callable): annealing schedule for temperature\n",
    "        gamma (float): friction coefficient\n",
    "        c (float): constant in logarithmic annealing schedule\n",
    "\n",
    "    Output:\n",
    "        f_list (numpy darray): the list of function values for each iteration\n",
    "        x_list (numpy darray): the list of x values for each iteration\n",
    "    \"\"\"\n",
    "    x_list = np.zeros((maxiter,d))\n",
    "    x_list[0,:] = x0\n",
    "    f_list = np.zeros((maxiter,))\n",
    "    f_list[0] = func(x0)\n",
    "    v_list = np.zeros((maxiter,d))\n",
    "    v_list[0,:] = np.zeros((d,)) \n",
    "\n",
    "    for i in range(1,maxiter):\n",
    "        epsilon = np.random.normal(0, 1, d)\n",
    "        beta = beta_schedule(beta0, i, c)\n",
    "        v_list[i,:] = v_list[i-1,:] - eta0*(gamma*v_list[i-1,:] + grad(x_list[i-1,:])) + np.sqrt(2*eta0*gamma/beta)*epsilon\n",
    "        x_list[i,:] = x_list[i-1,:] + eta0*v_list[i-1,:]\n",
    "        f_list[i] = func(x_list[i,:])\n",
    "    return f_list, x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7774964c-1296-455a-90bb-f5014cd9963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_skew_symmetric(n):\n",
    "    A = np.random.randn(n, n)*0.1\n",
    "    return A - A.T  # This ensures the matrix is skew-symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "345948b4-2460-4ff1-8d13-06532f438b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = Bounds([0], [np.inf])\n",
    "def nonreversible_langevin(x0, d, func, grad, maxiter = 100, eta0 = 0.001, beta0 = 1, beta_schedule = log_beta, c = 1):\n",
    "    \"\"\"\n",
    "    This code implements Non-reversible Langevin Algorithm with exact linesearch on the step size eta\n",
    "\n",
    "    Args:\n",
    "        x0 (numpy darray): initial point\n",
    "        d (int): dimension of the objective function\n",
    "        func (Callable): objective function\n",
    "        grad (Callable): gradient of objective function\n",
    "        maxiter (int): maximum number of iterations\n",
    "        eta0 (float): initial value for eta\n",
    "        beta0 (float): initial value for beta\n",
    "        beta_schedule (Callable): annealing schedule for temperature\n",
    "        c (float): constant in logarithmic annealing schedule\n",
    "\n",
    "    Output:\n",
    "        f_list (numpy darray): the list of function values for each iteration\n",
    "        x_list (numpy darray): the list of x values for each iteration\n",
    "    \"\"\"\n",
    "    x_list = np.zeros((maxiter,d))\n",
    "    x_list[0,:] = x0\n",
    "    f_list = np.zeros((maxiter,))\n",
    "    f_list[0] = func(x0)\n",
    "    AJ = random_skew_symmetric(d) + np.eye(d)\n",
    "\n",
    "    for i in range(1,maxiter):\n",
    "        epsilon = np.random.normal(0, 1, d)\n",
    "        beta = beta_schedule(beta0, i, c)\n",
    "        def objective_function(eta):\n",
    "            return func(x_list[i-1,:]- eta*grad(x_list[i-1,:]) + np.sqrt(2*eta/beta)*epsilon)\n",
    "        # perform exact linesearch\n",
    "        result = minimize(objective_function, eta0, method = \"SLSQP\", bounds=bounds)\n",
    "        eta = result.x\n",
    "        beta = beta_schedule(beta0, i, c)\n",
    "        x_list[i,:] = x_list[i-1,:] - eta*AJ.dot(grad(x_list[i-1,:])) + np.sqrt(2*eta/beta)*epsilon\n",
    "        f_list[i] = func(x_list[i,:])\n",
    "    return f_list, x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c4d3c9-ac10-473f-9c5f-98712948d00d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step_beta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_and_compare\u001b[39m(d, func, grad, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, eta0_gld\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, eta0_nld\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, beta0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, beta_schedule\u001b[38;5;241m=\u001b[39m\u001b[43mstep_beta\u001b[49m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, var\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    This code implements Gradient Langevin, Underdamped Langevin and Non-reversible Langevin and:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    1) plots the semi-log plot of average convergence curve;\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     gld_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'step_beta' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_and_compare(d, func, grad, maxiter=400, eta0_gld=1e-2, eta0_nld=1e-2, beta0=1, beta_schedule=step_beta, c=1, var=1, gamma=1):\n",
    "    \"\"\"\n",
    "    This code implements Gradient Langevin, Underdamped Langevin and Non-reversible Langevin and:\n",
    "    1) plots the semi-log plot of average convergence curve;\n",
    "    2) plots the boxplot of the final value of both algorithms;\n",
    "    3) computes Q1, median and Q3 of the final value of both algorithms;\n",
    "\n",
    "    Args:\n",
    "        d (int): dimension of the objective function\n",
    "        func (Callable): objective function\n",
    "        grad (Callable): gradient of objective function\n",
    "        maxiter (int): maximum number of iterations\n",
    "        eta0_gld (float): initial value for eta used in Gradient Langevin\n",
    "        eta0_nld (float): initial value for eta used in Non-reversible Langevin\n",
    "        beta0 (float): initial value for beta\n",
    "        beta_schedule (Callable): annealing schedule for temperature\n",
    "        c (float): constant in logarithmic annealing schedule\n",
    "        var (float): variance of the distribution where the initial point is sampled from\n",
    "        gamma (float): friction coefficient   \n",
    "    \"\"\"\n",
    "    gld_result = None\n",
    "    uld_result = None\n",
    "    nld_result = None\n",
    "    x = np.zeros((100,2))\n",
    "    gld_x = np.zeros((100,2))\n",
    "    uld_x = np.zeros((100,2))\n",
    "    nld_x = np.zeros((100,2))\n",
    "    for i in tqdm(range(100)):\n",
    "        x0 = np.random.normal(0,var, size=(2,))\n",
    "        x[i,:] = x0\n",
    "        f_list_gld, x_list_gld = langevin(x0, d, func, grad, maxiter=maxiter, eta0 = eta0_gld, beta0 = beta0, beta1=beta1, beta_schedule = beta_schedule, c=c)\n",
    "        f_list_uld, x_list_uld = underdamped_langevin(x0, d, func, grad, maxiter=maxiter, eta0 = eta0_gld, beta0 = beta0, beta1=beta1, beta_schedule = beta_schedule, c=c, gamma=gamma)\n",
    "        f_list_nld, x_list_nld = nonreversible_langevin(x0, d, func, grad, maxiter=maxiter, eta0 = eta0_gld, beta0 = beta0, beta1=beta1, beta_schedule = beta_schedule, c=c)\n",
    "        gld_x[i,:] = x_list_gld[-1,:]\n",
    "        uld_x[i,:] = x_list_uld[-1,:]\n",
    "        nld_x[i,:] = x_list_nld[-1,:]\n",
    "        f_list_gld = np.array(f_list_gld)\n",
    "        f_list_uld = np.array(f_list_uld)\n",
    "        f_list_nld = np.array(f_list_nld)\n",
    "        f_list_gld = f_list_gld.reshape((maxiter,1))\n",
    "        f_list_uld = f_list_uld.reshape((maxiter,1))\n",
    "        f_list_nld = f_list_nld.reshape((maxiter,1))\n",
    "        if i == 0:\n",
    "            gld_result = f_list_gld\n",
    "            uld_result = f_list_uld\n",
    "            nld_result = f_list_nld\n",
    "        else:\n",
    "            gld_result = np.concatenate((gld_result, f_list_gld), axis = 1)\n",
    "            uld_result = np.concatenate((uld_result, f_list_uld), axis = 1)\n",
    "            nld_result = np.concatenate((nld_result, f_list_nld), axis = 1)\n",
    "\n",
    "    # Extract final output\n",
    "    gld_final = gld_result[-1,:]\n",
    "    uld_final = uld_result[-1,:]\n",
    "    nld_final = nld_result[-1,:]\n",
    "\n",
    "    mean_gld = np.mean(gld_result, axis=1)\n",
    "    std_dev_gld = np.std(gld_result, axis=1)\n",
    "    mean_uld = np.mean(uld_result, axis=1)\n",
    "    std_dev_uld = np.std(uld_result, axis=1)\n",
    "    mean_nld = np.mean(nld_result, axis=1)\n",
    "    std_dev_nld = np.std(nld_result, axis=1)\n",
    "\n",
    "    plt.plot(np.arange(0,maxiter), np.log10(mean_gld), label = \"Gradient Langevin\")\n",
    "    plt.plot(np.arange(0,maxiter), np.log10(mean_uld), label = \"Underdamped Langevin\")\n",
    "    plt.plot(np.arange(0,maxiter), np.log10(mean_nld), label = \"Non-reversible Langevin\")\n",
    "    # plt.ylim(0,0.001)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Number of Gradient Evaluations\")\n",
    "    plt.ylabel(\"log(f(x_k) - f^*)\")\n",
    "    plt.savefig(\"mean_variant.jpg\")\n",
    "\n",
    "    plt.figure(figsize=(4,6))\n",
    "    sns.boxplot(data=[gld_final, uld_final, nld_final], palette='pastel')\n",
    "    plt.title(\"Boxplot of Final Objective Value\")\n",
    "    plt.ylabel(\"Function Value\")\n",
    "    plt.xticks([0,1,2], [\"GLA\", 'ULA', 'NLA'])  # if you just have one list\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.savefig(\"boxplot_variant.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "    gld_med = statistics.median(gld_final)\n",
    "    gld_mean = statistics.mean(gld_final)\n",
    "    # quartiles – split into 4 bins\n",
    "    q1, q2, q3 = statistics.quantiles(gld_final, n=4)  # q2 == median\n",
    "    print(\"Q1, Q2(median), Q3, mean for Gradient Langevin:\", q1, q2, q3, gld_mean)\n",
    "    \n",
    "    uld_med = statistics.median(uld_final)\n",
    "    uld_mean = statistics.mean(uld_final)\n",
    "    # quartiles – split into 4 bins\n",
    "    q1, q2, q3 = statistics.quantiles(uld_final, n=4)  # q2 == median\n",
    "    print(\"Q1, Q2(median), Q3, mean for Underdamped Langevin:\", q1, q2, q3, uld_mean)\n",
    "\n",
    "    nld_med = statistics.median(nld_final)\n",
    "    nld_mean = statistics.mean(nld_final)\n",
    "    # quartiles – split into 4 bins\n",
    "    q1, q2, q3 = statistics.quantiles(nld_final, n=4)  # q2 == median\n",
    "    print(\"Q1, Q2(median), Q3, mean for Underdamped Langevin:\", q1, q2, q3, nld_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a4fc8-981b-4085-8a9b-6d768cf1f30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
